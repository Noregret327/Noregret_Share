# FPGA综述

## ！！！老石！！！

### 1、FPGA行业的应用：

- 云数据中心
- 人工智能
- 高速网络处理
- 金融科技
- 数字医疗



### 2、FPGA发展的三个阶段

#### 1.发明阶段

由于芯片的流片成本巨大，业界需要一种通用的半导体器件，用来进行流片前的测试、验证等工作，从而减少流片失败的可能性。

<font color=Blue font size=4>第一片FPGA：</font>

- **55美元、2.5um工艺制造、64个逻辑单元、不超1000个逻辑门**
- 赛灵思的XC2064
- 20世纪80年代

#### 2.扩张阶段

20世纪末是摩尔定律大放异彩的时代。FPGA在1992年到1999年之间迎来自己的扩张阶段。出现“面积换性能”的电路设计方法，更大的芯片面积也给FPGA的架构创新提供了更多的想象空间。例如，FPGA可编程单元中的LUT查找表结构，从最初的三输入，开始变成四输入和六输入，甚至更多。（还逐渐增加了寄存器和多路选择器等更多额外功能。）

<font color=Blue font size=4>FPGA片上资源的互联复杂性已经开始取代逻辑结构的复杂性，并成为FPGA厂商需要优先解决的问题。还有一个主要变化是FPGA自动设计工具和软件的兴起。如：英特尔（原：Altera）的Quartus系列、赛灵思的ISE和vivado系列等。</font>

#### 3.积累阶段

进入21世纪，FPGA的发展进入积累阶段，FPGA的发展遇到瓶颈，因为单纯提升FPGA的容量已经不能满足各类应用的需求。（很多客户开始追求更高的性价比，并不愿意为过大的FPGA买单。）<font color=Blue font size=4>在这个大环境下，FPGA开始从单纯的可编程门阵列，逐步转变为拥有复杂功能的可编程片上系统。</font>

#### 4.超越维度的限制——3D FPGA

近年来，“摩尔定律已死”的声浪不绝于耳。

当芯片在水平维度的扩展逼近技术极限之后，开始在垂直方向上对芯片密度进行扩展，由此发明了3D芯片技术。

<font color=Blue font size=4>"3D芯片技术"主要有两种:</font>

- <font color=gree font size=4>赛灵思的堆叠硅片互联技术（SSI）</font>：SSI技术在封装基板和FPGA硅片之间加入了一层无源硅中介层，在硅中介层上可以放置多枚FPGA硅片，这些硅片通过在中介层里的硅通孔、微凸块以及大量连线进行相互连接。

<font color=green font size=4>缺点：</font>

1. 适用于每代半导体制造工艺的早期
2. 和完整一片硅片相比，多枚硅片通过硅中间层组合会降低芯片的性能。
3. 对FPGA配置的灵活性也可能造成很大影响，多枚FPGA硅片相当于人为地划分多个设计区域和硬边界，要对系统进行额外的逻辑划分。
4. 为了使用这种新的多硅片FPGA架构，FPGA设计工具需要进行一定程度的改动和优化。（时序优化和布局布线问题）

- <font color=gree font size=4>英特尔的嵌入式多管芯互联桥接技术（EMIB）：</font> 没有引入额外的硅中介层，而是只在两枚硅片边缘连接处加入了一条硅桥接层，并重新定制化硅片边缘的I/O引脚以配合桥接标准。

<font color=green font size=4>产生背景:</font>

1. 不同功能的IP，它们所对应的成熟或性价比更高的制造工艺不尽相同。
2. 不同IP的更新迭代速度不同。（典型的例子就是各类收发器IP与FPGA的整合）

<font color=green font size=4>与SSI相比的优点：</font>

1. 降低了系统的制造复杂度
2. 降低了不同硅片间的传输延时

<font color=green font size=4>使用：</font>

- 在Stratix10系列FPGA中，EMIB目前主要被用来进行FPGA与收发器以及高带宽存储器（HBM）的连接。
- 除了与HBM连接，还可以与多片FPGA硅片连接。

<font color=green font size=4>存在问题：</font>

1. 在一定程度上缓解工艺早期的良率问题。
2. 通过EMIB连接不同硅片后，可能会形成一个不规则的芯片结构。从而导致发热不均衡导致的应力、连接和可靠性的问题。

<font color=Blue font size=4>真3D封装技术：</font>

- Foveros：可以将CPU、GPU、DRAM、Cache等不同功能的硅片堆叠在一起，再封装成为一枚完成的芯片——2019年初英特尔公布



### 3、突破集成度边界——ACAP

2018年，<font color = red>**赛灵思**</font>推出了ACAP的芯片产品，它整合了硬件可编程逻辑单元、软件可编程处理器，以及软件可编程加速引擎的下一代计算平台。

2019年，<font color = red>**赛灵思**</font>公布了基于ACAP架构的首款产品：<font color = red>Versal</font>。（相比传统的FPGA架构，在系统架构、电路结构、互联方式等很多方面进行了大胆革新）

#### 1.芯片架构

Versal ACAP基于台积电的<font color = red>7nm</font>工业制造。总体来看，它与传统FPGA结构非常相似，主要包含可编程逻辑部分、高速I/O与收发器、嵌入式处理器、存储器控制等FPGA常见硬件资源与模块。

<font color=green font size=4>与传统相比：</font>

1. 芯片中固化一组AI加速引擎阵列。主要用来加速神经网络的推断计算和无线网络等应用中常见的数学计算和信号处理。
2. 在传统片上互连技术基础上，采用了固化的片上网络技术，主要针对高带宽、高吞吐量的应用场景。
3. 采用更加规整的可编程逻辑阵列和时钟域分布。（不用对整个设计重新编译，只需要单独处理修改部分即可）

#### 2.CLB微结构

CLB是可编程逻辑模块的缩写（Configurable Logic Block）。ACAP对它的CLB微结构进行了“翻天覆地”的重大革新。主要以下4点：

1. 与现有的UltraScale FPGA架构相比，ACAP中的CLB面积扩大了4倍。ACAP为每个CLB设置了单独的内部高速互联，与全局布线相比，内部互连更加快速，布线逻辑更加简单。
2. 每个查找表结构LUT增加了一个额外的输出。（传统FPGA的LUT结构曾经只有4个输入，当前大部分增加为6输入、2输入，实现任意6输入逻辑，或两个5输入逻辑）
3. 每个逻辑片的进位链逻辑结构进行了彻底修改。
4. 引入了“Imux寄存器”的新结构。

#### 3.第四代SSi技术

ACAP采用赛灵思第四代硅片堆叠技术SSI，针对SSI技术延时较高的主要缺点，ACAP在架构层面进行了大量优化。

#### 4.片上网络

在传统的FPGA布线资源之外，ACAP引入了固化的NoC网络，将需要进行高速数据传输的内容转化成基于数据包的形式，通过片上网络的交换机逻辑实现数据交换。

这种方法最大的优点：在系统层面将数据传输与数据计算进行了分离，从而在保证带宽的基础上，缓解了系统的布局布线压力。



### 4、灵活与敏捷共存——Agilex

2019年，Agilex是<font color = red>英特尔</font>最新一代<font color = red>10nm</font> FPGA，它是Agile（敏捷）和Flexible（灵活）的结合。

- 敏捷性指的是“异构”：它既可以是不同逻辑单元之间的异构，也可以是不同工艺的异构，或者两者兼而有之。（只有采用异构模式才能充分发挥不同IP和不同工艺节点的优势）
- 灵活性指的是可编程性：可编程逻辑阵列，可以灵活地针对不同应用场景进行编程，并改变FPGA的逻辑结功能。



英特尔的两个独门绝技：

- X86架构
- 半导体制造工艺



### 5、拥抱大数据洪流

随着人工智能、自动驾驶、5G、云计算等各种技术的不断发展，海量数据将会源源不断产生，预计到2025年，数据总量将比现在增长10倍。

- 有人形象的将数据比喻为人工智能时代的石油。
- 现如今只有不到1%的数据被进行了有效的处理、分析和利用。
- 数据中心是支持数据<font color = red>计算</font>与<font color = red>传输</font>最重要的环节——数据中心市场成为各大半导体与互联网公司必争之地



<font color=Blue font size=4>第一个吃螃蟹的人——微软Catapult</font>

2014年，微软在计算机架构领域的顶级会议ISCA上发表了一篇为A Reconfigurable Fabric for Accelerating Large-Scale Datacenter Services的论文。

主要讲诉的是Catapult的项目，将英特尔的Stratix V系列FPGA部署到了自家数据中心的1632台服务器中，并使用FPGA对必应搜索引擎的文件排名运算进行了硬件加速，最终得到了高达95%的吞吐量提升。













































## 一、FPGA 的发展历程

![image-20230720151411580](https://raw.githubusercontent.com/Noregret327/picture/master/202307201514772.png)



FPGA 的应用领域已经从原来的通信扩展到消费电子、汽车电子、工业控制、测试测量等更广泛的领域. 在学术界，FPGA 与深度神经网络结合的应用也得到越来越多的关注，成为研究热点.

## 二、FPGA与深度神经网络结合的产业应用现状

### 1.图像检测与识别

关于FPGA 上面部署图像识别的应用越来越多，如人脸识别[118–123]、人手姿态识别[124]、字符识别[125, 126]、车牌识别[127]、交通标志识别[128]、自然场景识别[91]等等.

如文献[129]就提出了一种稀疏的YOLO 检测模型，并在Intel Arria-10 GX1150 FPGA上达到了2.13 TOPS（72.5 fps）的吞吐量，并在PASCAL VOC2007 数据集上的检测精度达到了74.45%. 还有关于道路交通的目标检测工作，如行人检测[130–132]、车辆检测[133]与障碍检测[134]，用作车道偏离警告系统的多用途道路路径提取[135]等研究工作也在不断进行. 检测路上是否有行人、交通标志以及视野中是否存在汽车或其他车辆，这些均属于自动驾驶实现的基础工作. 在FPGA 上部署人脸识别系统[118, 119, 136]的研究已经很普遍了，并且场景也越来越多，如应用于移动视频会议、微型无人机和其他小型机器人的低功耗、轻量化嵌入式视觉
系统[119]. 为了适应不同场景的需求并且获得更好的用户体验，人们对于识别系统的速度也有了越来越高的要求. 因此，一部分研究工作是在FPGA 上部署图像识别算法，验证所提出的加速方案和架构[91,137]，加快算法计算速度，提高识别系统的识别速度. 图像检测与识别将成为自动驾驶场景的研究重点之一，同时也就对于FPGA 这种便携、低功耗设备有着一定的需求.



### 2.目标跟踪

目标跟踪最近几年发展迅速，不少研究者在研究如何在FPGA 上实现目标跟踪系统，从而推动产业应用. 目标跟踪系统在军事侦察、安防监控等诸多方面均有广泛的应用前景.

目前，较多研究主要是将FPGA 作为协处理器的目标跟踪系统，用于实时视觉跟踪[138–140]. 不同的实时视觉跟踪系统设计中使用的方法也不尽相同，如：mean shift 跟踪算法、hausdorff 距离算法、光流法等[138, 139, 141]，计算边缘/角点检测、静止背景和噪声滤波等优化操作也常常在实际中进行应用. 近年来，随着深度神经网络模型的不断发展，其跟踪网络性能明显优于传统方法.如：文献[142]中提出的MiniTracker，使用的是全卷积的Siamese 网络，并对其进行了剪枝和量化，使得其在ZedBoard 上实现并且达到了18.6 帧每秒的跟踪率.

跟踪系统设计中方法的选择主要是根据应用中使用者对于FPGA 设备要求的侧重点不同. 当然，多数侧重于实现低功耗和低成本的实时目标跟踪[139, 141, 143]. 设计者会在跟踪精确度与成本之间做一种均衡，在满足精度需求的基础上，尽可能降低功耗与成本. 因此，我们常常需要对部署的深度网络模型进行简化操作, 如以上提到的剪枝和量化操作.



### 3.语音识别

目前，深度神经网络除了在图像和视频领域应用越来越广泛以外，基于FPGA 的语音识别系统也成为研究热点. 由于其庞大的市场需求，语音识别发展速度异常迅猛. 在智能语音识别产品中，为保证一定的灵活性和移动性，往往在FPGA 上部署语音识别模型，以满足智能与生产落地的需求. 在其相关研究中，语音识别模型主要有连续隐马尔可夫模型、液体状态机以及递归神经网络[144] 等等. 其中，文献[145,146]主要在FPGA 上实现了马尔科夫模型的语音识别效果. 文献[147]在FPGA 上实现了液体状态机，并利用语音识别进行了评估. 与AMDOpteron TM 处理器的运行速度相比，该方法在FPGA 上实现了88x 运行加速. 文献[144]设计了一
种基于神经网络的实时语音识别系统，其包含将用于声学建模的语音特征，以及用于字符级语言建模的两个递归神经网络. Yong Zheng 等人在文献[148]中通过剪枝、量化等操作对LSTM 模型进行简化，在FPGA 上实现了一种高性能、高效的LSTM 接口.文献[149]提出了一种基于FPGA 主板的LSTM 神经网络硬件加速器. 作者也对LSTM 进行了稀疏剪枝操作并采用流水线方法，在实验性能上，其运行速度高于ARM Cortex-A9 处理器. 文献[150]主要提出使用一维的通用背景模型（1D CNN）对说话人进行识别. 与CPU 平台相比，它减少了ResNet20 的计算复杂度以及参数量使得其在FPGA 上的运行速度在3S 与5S 数据集上分别达到了5.1 和6.8 倍的加速. 文献[151]中提出的AIX 是针对于DNN 的商业语音识别应用设计的FPGA 加速接口. 文献[152]提出了基于梯度计算的LSTM，其与二进制的LSTM相比，在几乎不损失精度的情况下减少73.24%的能耗. 文献[153]中，作者将Toeplitz 结构应用于DNN模型上，在不计loss 的情况下实现了较高的压缩率.LSTM 在应用该方法后，模型尺寸减少了28.7 倍，在FPGA 上实现了130000 帧/秒的吞吐量.

在调查过程中，可以发现**LSTM 模型**已成为目前FPGA 部署的典型的语音识别模型，目前已经被成功并广泛地应用于人工智能应用中[154, 155]. 深鉴科技的ESE 语音识别引擎因其深度压缩技术引起了一时轰动. 在其为代表的相关研究表明，研究者主要希望将语音模型简化并部署在FPGA 上，从而实现高性能并且高效的语音识别效果. 我们相信，语音识别的应用领域将不断扩大，除了电子产品与通信领域，也终将进入医疗、工业等各个领域.



### 4.文本处理

典型代表有百度NLP语义计算整体框架，其中的核心部分就有包含FPGA 在内的高性能计算模块，以及基于深度神经网络和概率图模型的语义计算引擎. 除此以外，还有很多基于FPGA 上的常用的自然语言框架，如RNNLM 框架[156]、DNN的设计框架[157]、SimNet 语义匹配框架[158]、基于随机计算的深信度字符识别网络框架[159]等等. 文献[160]中主要将有效的CNNs 模型压缩，进而用于情绪分析. 其压缩过程包含了剪枝、量化，最后将压缩后的模型映射到FPGA 上进行实验，在准确性不下降的条件下，内存带宽占用比原始模型降低了85%~93%. 2018 年，谷歌提出的自然语言处理模型即BERT 模型[161]，一度成为NLP 的研究热点. 因为其可以在11 种不同NLP 测试中创造出最佳成绩. 随后，2019 年Facebook 提出的具有强大优化能力的BERT 方法RoBERTa 模型在GLUE、SQuAD 和RACE 三个排行榜上均实现了最优的结果. 文献[162]主要针对基于Transformer 的大规模语言表示提出了一种有效的加速框架Ftrans. 该框架可以将RoBERTa 模型压缩至原来尺寸的1/16 ， 实现27.07~81 倍的性能改进. 在能效方面，其比CPU 的能效高出8.8 倍.

将被广泛地应用于各种机器翻译，用户情感分析等产品中去. 同时，研究表明人们对于文本处理速度有着一定的要求，因此大量的研究将以简化语义模型以及提升FPGA 计算速度为目的进行展开.



### 5.网络安全

网络安全与入侵检测也是FPGA 与深度神经网络结合的一个重要应用，主要是对于网络系统中收集的信息进行分析，然后通过某种模型判断是否存在异常的行为. 基于FPGA 的网络安全与入侵检测系统就是为了对于网络进行实时监控，并在网络系统异常时或者对外来攻击进行及时的反应，以保证网络系统的安全性. 关于该方面的研究也越来越多[163–166]，有降低FPGA 的计算要求的深度神经网络算法实现在线异常入侵检测系统，也有利用可重构硬件辅助网络入侵检测系统，以及利用FPGA搭建了网络传输异常检测体系结构等. 这些系统往往都可以被集成在可重构系统中，作为辅助系统使用.



### 6.智能控制

基于FPGA 的深度神经网络系统还在智能控制领域得到了广泛的应用，如文献[167–171]等等. 文献[167]提出了一种基于人工神经网络的步进电机低速阻尼控制器，该控制器设计用于消除低速时的非线性干扰. 文献[168]介绍了在可编程自动化控制器上嵌入FPGA 的多层神经网络的实现，在安装在控制器内部的FPGA 中实现基于神经网络的状态估计，可以将开发的结构直接转移到实际应用中. 文献[169]提出了一种利用人工神经网络（ANN）实现强化学习方法Q-Learning的FPGA 实现方法，并将其用于行星探测器和航天器的智能控制系统. 该方法将神经网络自身的并行性与FPGA 的硬件的并行性进行匹配，大大提高了处理速度. 与传统的Intel i5 2.3 GHz CPU 相比，Virtex 7 fpga 的速度提高了43 倍. 文献[170]提出了一种最大功率点动态跟踪控制器，该动态控制器主要采用了基于级联神经网络（CNN）的MPPT 算法，从变速条件下的WPCS 中提取最大功率. 通过实验得出，与传统的MPPT 算法相比，基于级联神经网络的MPPT 算法的控制器的控制效率更高，能对风速改变提供更好的响应. 将基于FPGA 的深度神经网络用于实际控制，打破了传统逻辑控制模式，实现了控制系统的自动化和智能化.



## 三、FPGA 深度神经网络的加速与优化

深度神经网络往往是在大内存、较强计算力的GPU 上进行训练学习的. 但在相关模型进行产品化落地应用时，必须考虑设备资源的尺寸、内存、能耗、带宽和成本等因素. 神经网络模型压缩和加速的提出，让复杂的深度神经网络在小型设备（FPGA）上的实现成为了可能.

### 1.FPGA神经网络加速器

随着深度学习的不断发展，神经网络在图像、视频、语音处理等各个领域取得了巨大的成功.VGGNet、GoogleNet、ResNet 的出现，让我们清楚的看到神经网络正往更深、更复杂的网络设计方向发展. 那么，如何将更复杂的神经网络部署到FPGA上，并能够满足一定的速度要求，成为研究者们关注的焦点.DLAU[172] 、Deep-Burning[173] 、DeepX[174]、BISMO[175]、Bit Fusion[176]与为SGEMV设计的FPGA 加速器[177]等等.

- DLAU:采用动态调度的流水线化结构,支持各种CNN模型,优点是灵活性高,缺点是控制逻辑相对复杂。
- DeepBurning:使用Ping-Pong Buffer实现流水线操作,支持 CNN和RNN模型,优化内存访问,缺点是仅针对特定模型。
- DeepX:三维可编程结构,采用分布式存储架构,支持多种模型,缺点是资源利用率不高。
- BISMO:使用串行执行单元阵列,支持向量-矩阵运算,优点是节省资源,缺点是性能受限。
- Bit Fusion:混合精度设计,不同层使用不同位宽,优点是提高性能和效率,缺点是需要重新训练模型。
- SGEMV 加速器:专门针对基本线性代数运算 SGEMV 优化设计,优化数据流和存储,缺点是仅专注一个运算。

总体来说,这些设计都在交易 off 性能、灵活性、资源利用率,需要根据具体应用场景选择。趋势是向支持多种模型与运算的可编程架构发展。



### 2.神经网络压缩与加速技术

众所周知，深度神经网络在多个领域上表现出优于传统算法的效果. 但在应用过程中，其计算量巨大，占据内存较大. 因此，若想真正将神经网络应用到嵌入式系统中去，就必须对神经网络自身进行处理，以实现神经网络的压缩与加速.FPGA 加速设计中涉及的几种常见的神经网络压缩与加速方法：包含网络剪枝在内的深度压缩、低秩估计、模型量化以及知识蒸馏方法[178, 179].

- 深度压缩:通过剪枝、量化、哈夫曼编码压缩模型,优点是显著减小模型大小,缺点是需要重新训练。
- 低秩估计:使用低秩分解降低参数冗余,优点是加速计算,缺点是可能损失准确性。
- 模型量化:减少参数位宽来减小模型,优点是压缩比高,缺点是需要精心设计防止过度量化。
- 知识蒸馏:使用教师模型指导小模型学习,优点是模型压缩效果好,缺点是需要训练教师模型。

整体来说,这些方法通过牺牲某些指标来达到模型压缩和加速,需要根据具体情况平衡指标权衡。趋势是向支持多种混合压缩方法以获得更好效果。



### 3.计算加速与优化

1. 矩阵乘法优化:矩阵运算在深度神经网络的训练与前向计算中占据主导地位，因此加速矩阵运算具有重大意义.矩阵乘法的优化可以通过减少乘法计算次数和提高计算速度来实现. 矩阵分块技术与Winograd 转换方法常常作为神经网络中的优化算法. 

- 特点:改进矩阵乘法的计算和存储顺序,增加数据复用,优化内存访问模式。
- 优点:可以显著减少矩阵乘法的计算量和内存访问。
- 缺点:需要针对硬件做优化,不一定通用。

1. 卷积优化:神经网络结构往往是由卷积层，池化层以及全连接层构成的. 其中的卷积层和全连接层在硬件结构上，往往是针对于矩阵运算进行设计的. 将卷积
   层和全连接层可以转化为矩阵，然后利用FPGA 进行计算并加速.

- 特点:利用卷积运算的特点,采用Fourier变换、Winograd算法等对其进行算法层面的优化。
- 优点:可以大幅减少卷积层的计算复杂度。
- 缺点:存在数值误差,对硬件有一定依赖。

1. 频率优化:理论峰值工作频率也是FPGA 性能指标之一，提高FPGA 的峰值性能也是目前FPGA 加速设计中的一个研究方向[85,91,241]. FPGA 能够达到多少工作频率不仅需要考虑FPGA 芯片自身支持的频率是多少，同时需要考虑如何内部提高时钟频率，即如何对程序优化，来提高多用寄存器工作频率. 28nm 的Altera FPGA 上实现傅里叶变换等简单算法可以达到数百GFLOPS，QR 与Cholesky 分解等复杂算法则达到100 GFLOPS 以上. 比较新的FPGA 能够支
   持700-900MHz 的DSP 理论峰值工作频率，但现有的设计通常在100~400MHz 下工作[109, 116]. 因此，提高FPGA 工作频率，也是神经网络在FPGA 上进行部署的一个重点研究方向.

- 特点:降低处理器频率以换取更高效的计算。
- 优点:可以显著提升处理器的性能和效率比。
- 缺点:需要重新设计软硬件工作方式。

总之,这些优化方法根据运算特点进行算法或硬件层面的改进,可单独或联合使用。但也存在一定约束,需要确保数值精度。总体目标是在不损失准确性的前提下,尽可能提升计算性能和效率。



### 4.基于带宽的神经网络加速

在基于FPGA 的神经网络加速中，内存带宽也常常是影响计算速度的瓶颈. 当模型的计算强度小于计算平台的计算强度上限时，此时模型理论性能的大小完全由计算平台的带宽上限以及模型自身的计算强度所决定. 由此可见，在模型处于带宽瓶颈区间的前提下，计算平台的带宽越大，模型的理论性能可呈线性增长. 因此，通过提高带宽上限或者减小带宽需求，可以实现对模型的加速. 



### 5.基于FPGA 的神经网络编译器及框架

对于基于 FPGA 深度神经网络的研究，器件的选择和实验结果的分析评估是实验过程中不可忽视的两个部分. 其中，FPGA 的型号选择是实验顺利进行的先决条件，在此基础上对实验结果进行度量和分析，便可以从多个维度对实验进行分析和把控，从而得到较为全面的实验结果，有助于推进FPGA深度神经网络的研究进展.



## 四、FPGA的型号选择

FPGA 芯片内部资源主要包括**IO 资源、时钟资源、逻辑资源、RAM资源、DSP 资源、高速接口资源、硬核IP** 等，型号选择通常需要平衡各种资源需求并优先考虑关键资源的瓶颈. 

例如，在深度神经网络计算加速设计中，通常需要**优先考虑DSP 数量、BRAM 数量以及所支持的外部存储最大带宽**等.

 在选择具体的芯片型号以及封装时，要根据实验的需求与具体情况做出选择. 一般来说，可以从芯片特点、规模大小、速度需求、功耗等几个方面做综合的考量. 具体来说，芯片特点应该关注所选器件的高速接口、通道及各个通道需要的最高收发速度等信息；规模大小应该考虑所选器件系列和IP 的大致规模估计以及调试过程的资源消耗；速度需求应该根据所需功能进行选择；功耗则需要根据之前的设计、FPGA 供应商提供的功耗评估软件等估算将要消耗的功耗，从而确定所需的器件.

### 1.基于网络选择FPGA型号

不同的应用及网络模型常常适合不同的FPGA型号. 目前基于FPGA 的深度学习实验中，常用的网络模型有AlexNet、VGG、GoogleNet、ResNet、RNN 等. 其中以AlexNet 为实验模型时常选用Kintex-7、Virtex-7、Stratix-V 系列；以VGG 为实验模型时常选用Virtex-7、Stratix-V、Kintex-7、Arria-10系列；以GoogleNet 为实验模型时常选用Kintex-7、Arria-10 系列；以ResNet 为实验模型时常选用Arria-10、Kintex-7 系列；以RNN 为实验模型时常选用Kintex-7、Airtex-7、Arria-10、Virtex-6 系列. 具体系列选择如表3 所示.

![image-20230720155143590](https://raw.githubusercontent.com/Noregret327/picture/master/202307201551623.png)



### 2.基于应用的FPGA 型号选择

深度学习应用中常见的图像识别、目标跟踪、目标检测、语音识别等应用中常常使用Virtex-5、Virtex-2、Virtex-4系列的FPGA 芯片，除此之外，在自然语言处理中，研究者们还使用了Airtex-7 系列；在网络安全与入侵检测和电力应用中，Virtex-2 系列被用的最多. 每一种应用所常用的FPGA 芯片系列具体如表4 所示.

![image-20230720155159556](https://raw.githubusercontent.com/Noregret327/picture/master/202307201551585.png)









































## 参考文献

###### [118] Clément Farabet, Cyril Poulet, Jefferson Y Han, Yann LeCun. Cnp: An fpga-based processor for convolutional networks//2009 International Conference on Field Programmable Logic and Applications. Prague, Czech, 2009: 32-37

###### [119] Janarbek Matai, Ali Irturk, Ryan Kastner. Design and implementation of an fpga-based real-time face recognition system//2011 IEEE 19th Annual International Symposium on Field-Programmable Custom Computing Machines. Salt Lake City, Utah, 2011: 97-100

###### [120] Nikolaos Stekas, Dirk van den Heuvel. Face recognition using local binary patterns histograms (LBPH) on an FPGA-based system on chip (SoC)//2016 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW). Chicago, USA, 2016:300–304

###### [121] M Tousif Ahmed, Sanjay Sinha. Design and development of efficient face recognition architecture using neural network on FPGA//2018 Second International Conference on Intelligent Computing and Control Systems (ICICCS). Wuhan, China, 2018: 905-909

###### [122] Phan-Xuan H, Le-Tien T, Nguyen-Tan S. FPGA platform applied for facial expression recognition system using convolutional neural networks. Procedia Computer Science, 2019, 151: 651- 658

###### [123] Zeeshan Ahmed Soomro, Tayab Din Memon, Falak Naz, Ahmed Ali. FPGA based real-time face authorization system for electronic voting system//2020 3rd International Conference on Computing, Mathematics and Engineering Technologies (iCoMET). East Sarajevo, Bosnia and Herzegovina, 2020: 1-6

###### [124] Al Koutayni M R, Rybalkin V, Malik J, et al. Real-time energy efficient hand pose estimation: A case study. Sensors, 2020, 20(10): 2828-2853

###### [125] Kenneth L Rice, Mohammad A Bhuiyan, Tarek M Taha, Christopher N Vutsinas, Melissa C Smith. FPGA implementation of izhikevich spiking neural networks for character recognition// 2009 International Conference on Reconfigurable Computing and FPGAs. Quintana Roo, Mexico, 2009: 451-456

###### [126] Lammie C, Hamilton T, Azghadi M R. Unsupervised character recognition with a simplified FPGA neuromorphic system// IEEE International Symposium on Circuits and Systems (ISCAS).Florence, Italy, 2018: 1-5

###### [127] Caner H, Gecim H S, Alkar A Z. Efficient embedded neural-net work-based license plate recognition system. IEEE Transactions on Vehicular Technology, 2008, 57(5): 2675-2683

###### [128] Yan Han, Erdal Oruklu. Real-time traffic sign recognition based on Zynq FPGA and ARM SoCs//IEEE International Conference on Electro/Information Technology. Milwaukee, USA, 2014: 373-376

