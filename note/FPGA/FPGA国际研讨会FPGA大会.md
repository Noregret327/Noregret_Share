# FPGA国际研讨会/FPGA大会

ACM/SIGDA International Symposium on Field-Programmable Gate Arrays

ACM 现场可编程门阵列国际研讨会 。

始于1993年，每年举办地点：美国加州的滨海城市Monterey。每年会议接收并全文发表的文章大约30篇，还有不少海报论文，以及各种讲座、演示、讨论等。全文发表的文章每篇10页，工作量和质量都堪比期刊论文。

# FPGA '22

FPGA '22：2022 年 ACM/SIGDA 现场可编程门阵列国际研讨会虚拟活动 美国 27年2022月1日至2022年<>月<>日

ACM FPGA是展示FPGA技术各个方面的令人兴奋的新研究的首要论坛，其中包括：

- <font color=Blue>新型 FPGA 架构和电路。</font>
- <font color=Blue>FPGA CAD 工具在技术映射、布局、布线等领域的进步。</font>
- <font color=Blue>允许在更高抽象级别进行 FPGA 设计的高级设计方法。</font>
- <font color=Blue>FPGA 的新应用，特别是高能效和高性能计算。</font>

项目委员会共收到<font color = red>**72篇**</font>符合投稿准则的论文，并进行了评审。总体而言，<font color = red>**25%的综述论文**</font>被接受发表。今年的计划为期3天，包括<font color = red>**15篇完整的研究论文（10页）和3篇简短的研究论文（6页）**</font>，以及4个受邀研讨会或教程和2个特邀主题演讲。主题演讲在论文集中发表了扩展摘要。此外，我们还有18份提交的作品作为海报呈现，作为摘要出现在这些会议记录中。



## 一、RapidStream: Parallel Physical Implementation of FPGA HLS Designs

### 《RapidStream: FPGA HLS设计的并行物理实现》

我们的研究产生了RapidStream，这是一个并行和物理集成编译框架，它接受C/C++中的HLS数据流程序，并生成完全放置和路由的实现。当在具有一组逼真的HLS设计的Xilinx U250 FPGA上进行测试时，与商用现成工具链相比，RapidStream在编译时减少了5-7倍，频率提高了1.3倍。此外，我们使用定制的开源路由器提供初步结果，以在性能要求较低的情况下将编译时间减少到一个数量级。该工具是开源的 atgithub.com/Licheng-Guo/RapidStream。

![image-20230824110924472](https://raw.githubusercontent.com/Noregret327/picture/master/202308241109563.png)

在这项工作中，我们提出了RapidStream，这是一种分割编译流程，具有紧密集成HLS级流水线和物理设计，以加快端到端FPGA编译。如图 2 所示，我们的方法包括三个主要阶段。在分区阶段，我们将 FPGA 设备组织为不相交岛的网格，并将数据流设计布局到孤岛中；然后，我们利用 HLS 的灵活性将管道寄存器插入到岛间网络中，我们称之为锚寄存器。锚寄存器在岛之间提供了关键的时序隔离，以实现并行实现。最后，我们将每个岛的布局结果拼接在一起，生成完整的实现。

与也使用拆分编译方法的现有技术[62]相比，RapidStream有几个不同的特征。首先，我们实现了完全自动化，而[62]过度依赖手动输入，包括设计修改、布局规划、引脚分配等。其次，我们实现了接近400 MHz的时钟频率，但[62]只报告了187 MHz的频率。一个关键的区别是[62]依赖于固定的预路由覆盖结构来隔离岛，但代价是灵活性和时序质量。相比之下，RapidStream 可以利用特定于设计的优化，而不使用预先配置的覆盖，这有助于改进时序。我们将在第 8 节中提供详细的比较。

关键技术贡献总结如下：

- 据我们所知，我们是第一个提出自动化、并行和物理集成流的人，将HLS数据流设计映射到完全放置和路由的FPGA实现，同时实现快速定时关闭。
- 我们确定并解决实际拆分编译流程的几个技术挑战。具体来说，我们提出了一种新的有效的方法:(1)插入管道寄存器，并在分区的延迟容忍边界优化它们的放置，(2)并行路由中的时钟管理，(3)跨岛网的高效孤岛拼接和路由。
- 我们的评估表明，所提出的方法显著增加了fpga目标分割编译的并行度。RapidStream 平均使用 ∼26 个内核，而商业 CAD 工具平均仅使用大约两个内核。因此，我们在商业工具上实现了 5-7 倍的端到端加速。此外，我们在频率上实现了高达 1.3 倍的改进。





## 二、Sextans: A Streaming Accelerator for General-Purpose Sparse-Matrix Dense-Matrix Multiplication

### 《Sextans：通用稀疏矩阵密集矩阵乘法的流加速器》

在本文中，我们介绍了 Sextans，这是一种通用 SpMM 处理的加速器。Sextans加速器特性(1)使用片上存储器的快速随机访问，(2)对片外大矩阵的流访问，(3)使用II=1管道平衡工作负载的PE感知非零调度，以及(4)硬件灵活性，使硬件原型化一次，以支持不同大小的SpMM作为通用加速器。我们利用高带宽内存 (HBM) 来有效地访问稀疏矩阵和密集矩阵。在评估中，我们提出了一个 FPGA 原型 Sextan，它在 Xilinx U280 HBM FPGA 板上可执行，以及一个投影原型 Sextans-P，具有更高的带宽与 V100 竞争和更多的频率优化。我们在广泛的稀疏矩阵上对 1,400 个 SpMM 进行了全面评估，包括来自 SNAP 的 50 个矩阵和来自 SuiteSparse 的 150 个矩阵。我们将 Sextan 与 NVIDIA K80 和 V100 GPU 进行比较。与 K80 GPU 相比，Sextans 实现了 2.50 倍的地理平均加速，而 Sextans-P 在 V100 GPU 上实现了 1.14 倍的地理平均加速（K80 比 4.94 倍）。该代码可在 https://github.com/linghaosong/Sextans 获得。

SpMM加速器的设计面临着许多挑战：

- 挑战 1 - 工作负载不平衡使得 SpMM 难以并行化。基于行的并行化 [6, 74, 80] 将一行的处理分配给处理引擎或线程（块）的任务。然而，由于每行中非零的随机分布，早期完成时间的处理引擎将空闲。为了克服工作负载不平衡，提出了基于非零的并行化[32,55,71](或图处理加速中的类似边缘进入处理[16,62,70,94])。然而，基于非零的并行化可能会在加速器微架构级别产生读写后的依赖关系，这导致调度的初始间隔更大(II)。
- 挑战 2 - 低效的内存访问是另一个挑战。由于SpMM的矩阵很大，不适合芯片，因此它们存储在片外存储器中。SpMM 的处理会导致对矩阵 A、矩阵 B 和矩阵 C 的随机读取访问，以及对 C 的随机写入访问。解决对片外存储器的大量随机访问是非常低效的。
- 挑战3 -如何设计一个通用的加速器，不需要重新运行合成/放置/路由的耗时流。虽然许多加速器被设计用于提高深度学习[5,11,12,23,31,35,64 - 69,77,87,88]等许多应用领域的计算效率和效率，但密集线性代数[23,29,30,35,77]，图处理[4,17,25,26,39,70,89,91,92,95]，基因组和生物分析[8,9,13,14,33,38,51,76,81]，数据排序[10,52,60,63]，大多数都是针对输入和输出大小固定的一个特定问题设计的。对于 FPGA 加速器，即使使用 [17, 77] 等改进工具，由于合成和放置/路由时间长，新设计仍然会消耗许多小时甚至几天的时间。此外，这是一个噩梦对于不是加速器专家定制和重新运行流程的最终用户，为他们的应用程序生成加速器。







## 三、Logic Shrinkage: Learned FPGA Netlist Sparsity for Efficient Neural Network Inference

### 《逻辑收缩：学习 FPGA Netlist 稀疏性的高效神经网络推理》

使用本机LUT作为独立可训练推理算子的fpga特定DNN架构已被证明可以实现良好的面积精度和能量精度权衡。该领域的第一项工作 LUTNet 在标准 DNN 基准测试中展示了最先进的性能。在本文中，我们提出了这种基于LUT的拓扑的学习优化，导致比直接使用现成的、手工设计的网络更高的效率设计。此类架构的现有实现需要手动规范每个 LUT 的输入数量。选择适当的先验是具有挑战性的，即使在高粒度（例如每层）这样做是一个耗时且容易出错的过程，它使 FPGA 的空间灵活性没有得到充分利用。此外，先前的工作看到随机连接的LUT输入，这不能保证网络拓扑的良好选择。为了解决这些问题，我们提出了逻辑收缩，这是一种细粒度的网表修剪方法，可以在针对 FPGA 推理的神经网络中为每个 LUT 自动学习。通过删除被确定为低重要性的LUT输入，我们的方法提高了合成加速器的效率。我们的 GPU 友好的 LUT 输入去除解决方案能够在其训练期间处理大型拓扑，但减速可以忽略不计。通过逻辑收缩，我们更好地将CIFAR-10分类为1.54×和1.31×的CNV网络性能最好的LUTNet实现的面积和能量效率，同时匹配其准确性。该实现还达到了同样准确、重度修剪的BNN的面积效率的2.71×。在具有 Bi-Real Net 架构的 ImageNet 上，使用逻辑收缩会导致 2.67 倍与 LUTNet 的合成后面积减少，从而允许在当今最大的 FPGA 上以前不可能实现。

#### FPGA-定制DNN架构

基于lut的DNN推理加速器已被证明在部署在fpga上时取得了显著的性能。NullaNet [12] 和 LogicNets [18] 被考虑到小规模分类任务，他们在每秒数亿个样本中达到了数十纳秒的延迟和吞吐量。除了fpga定制的网络设计之外，我们提出的LUTNet拓扑可以通过随机梯度下降[20]进行训练。LUTNet的可训练网表与修剪等常见的机器学习优化策略兼容，从而为提高性能和效率提供了机会。此外，LUTNet 方法适用于跨越广泛规模的任务，包括 ImageNet 分类。

由于DNN节点和LUT之间的一对一映射，LUTNet网表往往很大。因此，在典型的部署中，只有一部分网络层是逻辑扩展的：其余的被保留为标准的 BNN 结构。我们还提出了LUTNet体系结构的时间复用版本，它通过重新引入运行时变量权重[21]来否定每个LUT特定于单个节点的需求。这增加了LUTNet的可扩展性，但由于LUT专门化中的自由度丢失，它还降低了其相对于BNN的潜在面积和能量效率增益。

我们使用LUTNet网表作为逻辑收缩的起点，并证明了所得到的设计更具面积和能量效率。我们的自动化设计流程保持了LUTNet的部署灵活性、可扩展性和易用性。为了评估逻辑收缩在最通用设置中的潜力，我们假设使用硬化权重，与普通 LUTNet 一致。我们的方法可以应用于时间复用架构，但是我们同样希望这样做的收益较低。





## 四、Towards Agile DNN Accelerator Design Using Incremental Synthesis on FPGAs

### 《基于fpga增量合成的敏捷DNN加速器设计》

<font color=Blue>硬件软件协同设计是深度神经网络和 FPGA 加速器开发的新趋势，它迭代地修改和调整整个系统。</font>该方法的瓶颈在于耗时的硬件合成。在本文中，我们<font color=RED size=4>提出了一个增量合成框架Acoda来快速设计fpga上的DNN加速器。</font>基于对 DNN 的大多数修订都很小且本地的观察，Acoda 重用现有的硬件模块并逐步修改加速器。它首先使用图编辑距离算法检测软件修订。然后，它通过多级重用层次结构将软件修订映射到硬件修订。因此，Acoda 将设计过程速度提高了 9.31X 到 34.17X，并取得了与现成加速器相当的性能结果。

**DNN——Deep neural networks**

在商业硬件平台中，<font color=Blue>fpga在原型加速器方面</font>变得司空见惯，因为它们提供了高性能和能源效率[2,14,15,24,25,28,31,32]。更重要的是，FPGA加速器也可以在特定于应用程序的场景[1]中与dnn共同设计，因为fpga是可定制的。

![image-20230825102256871](https://raw.githubusercontent.com/Noregret327/picture/master/202308251022908.png)

DNN加速器的典型设计流程如图1所示。

用户提出了DNN拓扑、训练和部署它们与现有框架的fpga。DNN 在加速器上执行以测量设计质量。根据质量，用户将修改 DNN 结构或调整一些参数。该过程一直持续到加速器满足用户的要求。协同设计流程涉及两个编译步骤：软件编译和硬件合成。软件编译步骤将在将 DNN 编译为设计源代码时花费几秒钟或几分钟。硬件合成步骤将设计源代码合成到硬件的最终物理实现中，这涉及到fpga上的一系列冗长通道，包括HLS、逻辑合成、P&R。合成时间取决于工具、设计大小、频率等。HLS、逻辑合成和P&R都花了几个小时，使得硬件合成速度比软件编译慢几个数量级，也是协同设计的主要障碍。然而，在当前的设计流程中，我们必须遍历 FPGA 上的整个合成通道，以便对 DNN 进行细微的更改。

![image-20230825102929637](https://raw.githubusercontent.com/Noregret327/picture/master/202308251029676.png)

<font color=RED size=4>Acoda 可以通过计算图编辑距离来自动检测常见的 DNN 修订。然后，我们提出了一种基于DNN图的三级重用层次结构，尽可能地重用硬件设计，逐步合成设计。三个重用级别包括子图重用、节点重用和部分重用。</font>修改后的硬件模块将重新实现并集成到设计中，而其余部分保持不变。总而言之，我们的主要贡献是：

- 我们开发了一个增量合成框架Acoda，用于在fpga上设计DNN加速器。Acoda可以有效地缩短协同设计过程中的硬件开发时间。
- 我们确定了软件修订模式，并开发了一种图算法来检测DNN图。
- 我们开发了一个重用层次结构，具有不同的硬件重用级别和合成开销，以应对DNN修订。

实验表明，Acoda实现了Xilinx FPGA的9.31X到34.17X协同设计时间减少。与现成的加速器相比，Acoda 生成的设计提供了相当的性能。

![image-20230825104014560](https://raw.githubusercontent.com/Noregret327/picture/master/202308251040601.png)



[1]Best of Both Worlds: AutoML Codesign of a CNN and its Hardware Accelerator——两全其美：CNN 及其硬件加速器的 AutoML 协同设计

 神经结构搜索(NAS)在准确性方面已经非常成功地超越了人类设计的卷积神经网络(CNN)，当硬件信息存在时，延迟也是如此。然而，nas设计的cnn通常具有复杂的拓扑结构，因此，可能很难为此类cnn设计定制的硬件(HW)加速器。我们通过包含CNN模型和HW加速器的参数，使用NAS实现HW-CNN协同设计的自动化，并共同搜索提高准确性和效率的最佳模型-加速器对。我们称之为Codesign-NAS。在本文中，我们重点定义了codesign - nas多目标优化问题，证明了它的有效性，并探索了导航协同设计搜索空间的不同方法。对于CIFAR-10图像分类，我们列举了近40亿个模型-加速器对，并在这个大的搜索空间中找到帕累托边界。这允许我们评估三种不同的基于强化学习的搜索策略。最后，与ResNet在HW设计空间中使用的最优HW加速器相比，我们在仅运行约1000 gpu小时的Codesign-NAS的情况下，将CIFAR-100分类精度提高了1.3%，同时性能/面积提高了41%。

[2]Shortcut Mining: Exploiting Cross-Layer Shortcut Reuse in DCNN Accelerators——快捷方式挖掘：利用 DCNN 加速器中的跨层快捷方式重用

各种特定于应用程序的 DNN 已在 FPGA 上实现。例如，[31,33]设计了用于实时目标检测的加速器。[2]提出了一种用于对象分类的加速器，它利用了ResNet[7]中的跨层快捷方式。一般来说，这些 DNN 通常由常用的模式或结构组成。



## 五、N3H-Core: Neuron-designed Neural Network Accelerator via FPGA-based Heterogeneous Computing Cores

### 《N3H-Core：基于 FPGA 的异构计算核心的神经元设计的神经网络加速器》

通过软硬件协同设计方法，在这项工作中，我们<font color=BLUE size=4>开发了一种基于fpga的神经网络加速异构计算系统</font>。

从硬件的角度来看，所提出的加速器由基于<font color=red> DSP 和 LUT 的 GEneral MatrixMultilication (GEMM) 计算内核组成</font>，这些内核以异构的方式形成整个计算系统。基于 DSP 和 LUT 的 GEMM 内核是在统一的指令集架构 (ISA) 和统一缓冲区上计算的。随着神经网络推理路径的数据流，卷积/全连接层的计算分为两部分，由基于 DSP 和 LUT 的 GEMM 内核异步处理。

从软件的角度来看，我们对所提出的异构加速器的延迟和资源利用进行了数学和系统建模，涉及不同的系统设计配置。通过利用强化学习技术，我们构建了一个框架来实现目标异构加速器设计规范的端到端选择和优化，包括工作负载拆分策略、混合精度量化方案以及DSP-和LUT-core的资源分配。由于所提出的设计框架和异构计算系统，我们的设计优于最先进的Mix&Match设计，延迟降低了1.12-1.32×，推理精度更高。N3H-Core 在以下网址开源：https://github.com/elliothe/N3H_Core。

众所周知，DNN推理的主要操作是乘法和累加(MAC)[4]。由于 FPGA 中的数字信号处理 (DSP) 单元可以有效地执行 MAC，因此基于 FPGA 的 DNN 加速器设计大量使用 DSP 资源来构建处理元素（又名。DSP-core) 作为 DNN 推理引擎。相比之下，作为 FPGA 的另一个重要片上资源，Look-Up 表 (LUT) 仅用于构建执行批量归一化、激活等计算的外围计算单元。

综上所述，基于 FPGA 的 DNN 加速器的初步架构设计主要应对以下缺点：

1)没有很好地利用丰富的片上 LUT 资源； 

2)不存在支持混合精度操作的高性能架构； 

3)缺乏单芯片异构系统的系统设计方法。 

作为对策，在这项工作中，我们提出了一种异构计算架构，该架构充分利用了片上资源（包括 LUT、DSP、BRAM 等）进行计算而不是控制。我们提出的架构由 LUT-core 和 DSP-core 组成，它们共同用作高性能计算系统。这两个计算内核分别处理具有灵活和固定位宽操作数的计算。为了便于在大型设计空间上优化复杂系统配置的人力，我们将端到端优化框架开发为所提出的单芯片异构系统的系统设计方法。我们的贡献可以概括为：

- 为了充分利用目标FPGA的片上资源，我们提出了一种异构DNN加速器架构，称为N3H-Core，它由DSP和LUT中心计算单元组成(又名。DSP-core 和 LUT-core）。
- 对于最大吞吐量和最小延迟，我们设计了 DSP 和 LUT-core 以层内异步方式操作预定义的指令。
- 我们构建了跨不同 DNN 和 FPGA 的可扩展且适应性的成本模型，以准确估计资源利用率、推理延迟和其他感兴趣的指标。
- 通过 N3H-Core 的成本模型，我们应用强化学习 (RL) 技术来构建端到端优化框架，该框架分别自动生成架构配置（资源分配）、数据流（逐层工作负载拆分比）和 DNN（权重和激活的量化位宽）。因此，给定目标DNN和FPGA平台，可以快速实现灵活、最优的设计。



## 六、HP-GNN: Generating High Throughput GNN Training Implementation on CPU-FPGA Heterogeneous Platform

### 《HP-GNN:在CPU-FPGA异构平台上生成高吞吐量GNN训练实现》

图神经网络 (GNN) 在许多应用中取得了巨大成功，例如推荐系统、分子属性预测、交通预测等。最近，CPU-STM 异构平台已被用于通过利用可定制的数据路径和丰富的 NVIDIA 可控制的芯片内存资源来加速许多应用。然而，在这些平台上加速和部署 GNN 训练不仅需要硬件设计的专业知识，还需要付出巨大的开发努力。

我们提出了 HP-GNN，这是一个新颖的框架，<font color=BLUE size=4>可以在给定的 CPU-FPGA 平台上生成高吞吐量 GNN 训练实现</font>，该平台可以使应用程序开发人员和机器学习研究人员受益。HP-GNN 将 GNN 训练算法、GNN 模型作为输入，并在目标 CPU-FPGA 平台上自动执行硬件映射。

HP-GNN 包括：

1. 减少内存流量和随机内存访问的数据布局和内部表示；
2. 支持各种 GNN 模型的优化硬件模板；
3. 用于自动硬件映射的设计空间探索引擎；
4. 高级应用程序编程接口 (API)，允许用户仅使用几行代码指定 GNN 训练。

为了评估 HP-GNN，我们尝试了两种著名的基于采样的 GNN 训练算法和两个 GNN 模型。对于每个训练算法和模型，HP-GNN 在最先进的 CPU-FPGA 平台上生成实现。与仅 CPU 和 CPU-GPU 平台相比，实验结果表明生成的实现平均分别实现了 55.67 倍和 2.17 倍的加速。与最先进的 GNN 训练实现相比，HP-GNN 实现了高达 4.45 倍的加速。

提出了 HP-GNN，这是一个在 CPU-FPGA 异构平台上映射 GNN 训练的框架。我们首先制定了一个高级抽象来描述基于采样的小批量 GNN 训练的计算。然后我们基于 GNN 抽象开发优化的硬件模板。为了减少开发工作并消除对硬件专业知识的需求，HP-GNN 提供了易于使用的软件编程 API，允许在不需要硬件编程的情况下快速开发。为了实现高吞吐量和自动化加速器生成过程，我们开发了一个通用的设计基于所选GNN训练算法优化硬件配置的空间探索引擎。

- 我们提出了一个通用框架，用于将各种基于采样的小批量 GNN 训练映射到 CPU-FPGA 平台上。
- 我们证明了HP-GNN对各种采样算法和GNN模型的适用性。
- 我们提供了抽象硬件实现细节的高级且易于使用的软件编程接口。
- 为了实现硬件映射和高吞吐量GNN训练，该框架包括以下优化：
- -数据布局和内部表示，减少了GNN不规则计算模式造成的内存流量和随机内存访问。
- -支持各种广泛使用的GNN模型的优化硬件模板。
- -通用设计空间探索算法，生成硬件设计配置，以优化各种采样方法和算法参数的训练吞吐量。
- 我们使用两个最先进的GNN模型来评估我们的框架：GraphSAGE[14]、GCN[17]以及两种常用的采样方法：邻居采样[14]和子图采样[29]。在 64 核 AMD 处理器托管的 Xilinx Alveo U250 板上运行，实验结果表明，与最先进的 CPU-GPU 平台上的 GNN 框架相比，我们的框架产生的加速器平均可以实现 2.17 倍的吞吐量。



## 七、Multi-input Serial Adders for FPGA-like Computational Fabric

### 《用于类似fpga的计算Fabric的多输入串行加法器》

<font color=blue size=4>提出了一种新的功能单元来取代类似fpga的计算结构中的LUT，该计算结构专门用于加速特定于实例的稀疏整数矩阵乘法。</font>我们使用一套矩阵、VPR布局和路由工具以及互连的现代架构表示来检查这种架构思想。称为 K-ADD 的新单元将密度提高了 2.5 倍到 4 倍，并通过同时增加时钟速率和减少计算乘积的循环次数，将性能提高了 8% 到 30%。这种好处放大了使用先前工作中演示的实例特定矩阵乘数的二阶优势。

双输入串行加法器可以推广到接受输入。与双输入情况一样，这种泛化将每个周期产生序列化输入总和的最低有效位，并在内部维护更重要的求和位。我们将此泛化称为 K-ADD。



## 八、How to shrink my FPGAs——Optimizing Tile Interfaces and the Configuration Logic in FABulous FPGA Fabrics

### 《如何缩小我的fpga——优化Fabulous FPGA Fabric中的平铺接口和配置逻辑》

本文致力于改进 FPGA 瓦片的物理实现和 SRAM FPGA 中的配置存储。本文提出了一种重新映射配置位和接口线来实现紧密打包的瓷砖。使用 Fabulous FPGA 框架，我们表明我们的优化几乎免费，但可以节省超过 20% 的面积并同时提高延迟。我们将通过改变可用的金属层或请求的通道容量在不同的场景中评估我们的方法。我们的优化考虑了所有瓦片，我们提出了一个流来解决 CLB 与其他瓦片之间的依赖关系。此外，我们将展示基于帧的重新配置在几乎所有情况下都优于移位寄存器配置。

![image-20230828105230480](https://raw.githubusercontent.com/Noregret327/picture/master/202308281052539.png)

Fabulous[20]集成了ASIC生成、仿真(未显示)和eFPGA配置比特流生成的学术和工业工具。





## 九、HeteroFlow: An Accelerator Programming Model with Decoupled Data Placement for Software-Defined FPGAs

### 《HeteroFlow：一种用于软件定义 FPGA 的解耦数据放置的加速器编程模型》

为了在配备 FPGA 的异构计算系统中实现高性能，联合优化数据放置和计算调度以最大化片上和片外内存访问的数据重用和带宽利用率至关重要。然而，<font color=blue size=4>优化 FPGA 加速器的数据放置是一项复杂的任务。</font>必须深入了解目标 FPGA 设备及其相关内存系统，以便应用一组高级优化。即使使用最新的高级合成 (HLS) 工具，程序员通常必须插入许多低级供应商特定的 pragmas 并显着重构算法代码，以便使用正确的通信方案在正确的循环级别访问正确的数据。这些代码更改可以显着损害原始程序的可组合性和可移植性。

<font color=blue size=4>为了应对这些挑战，我们提出了 HeteroFlow，这是一种 FPGA 加速器编程模型，它将算法规范与编排数据在定制内存层次结构中放置的优化解耦。</font>具体来说，我们引入了一个名为的新原语。to()，它提供了一个统一的编程接口，用于指定不同粒度级别的数据放置优化：（1）主机和加速器之间的粗粒度数据放置，（2）加速器内的中等粒度内核级数据放置，以及（3）内核内的细粒度数据放置。我们在开源 HeteroCL DSL 和编译框架之上构建 HeteroFlow。一组真实基准的实验结果表明，HeteroFlow编写的程序可以与高度优化的手动HLS设计的性能相匹配，代码行数要少得多。









































